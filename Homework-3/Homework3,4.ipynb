{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Datasets and Data Preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path =\"/Users/sumanthkakani/Documents/EE559-Mathematical-Pattern-Recognition/Homework-3/AReM/\";\n",
    "col=['time', 'avg_rss12','var_rss12', 'avg_rss13','var_rss13','avg_rss23','var_rss23'];\n",
    "\n",
    "bending1_df1 = pd.read_csv(path + \"bending1/dataset1.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df2 = pd.read_csv(path + \"bending1/dataset2.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df3 = pd.read_csv(path + \"bending1/dataset3.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df4 = pd.read_csv(path + \"bending1/dataset4.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df5 = pd.read_csv(path + \"bending1/dataset5.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df6 = pd.read_csv(path + \"bending1/dataset6.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df7 = pd.read_csv(path + \"bending1/dataset7.csv\", skiprows=4, header=0, names=col).values; \n",
    "\n",
    "\n",
    "\n",
    "bending1_test_df = pd.concat([bending1_df1,bending1_df2]) \n",
    "bending1_train_df = pd.concat([bending1_df3,bending1_df4,bending1_df5,bending1_df6,bending1_df7])\n",
    "\n",
    "\n",
    "bending2_df1 = pd.read_csv(path + \"bending2/dataset1.csv\", skiprows=4, header=0, names=col); \n",
    "bending2_df2 = pd.read_csv(path + \"bending2/dataset2.csv\", skiprows=4, header=0, names=col); \n",
    "bending2_df3 = pd.read_csv(path + \"bending2/dataset3.csv\", skiprows=4, header=0, names=col); \n",
    "bending2_df4 = pd.read_csv(path + \"bending2/dataset4.csv\", skiprows=4, header=0, names=col); \n",
    "bending2_df5 = pd.read_csv(path + \"bending2/dataset5.csv\", skiprows=4, header=0, names=col); \n",
    "bending2_df6 = pd.read_csv(path + \"bending2/dataset6.csv\", skiprows=4, header=0, names=col); \n",
    "bending2_test_df = pd.concat([bending2_df1,bending2_df2]) \n",
    "bending2_train_df = pd.concat([bending2_df3,bending2_df4,bending2_df5,bending2_df6])\n",
    "\n",
    "\n",
    "\n",
    "walking_df1  = pd.read_csv(path + \"walking/dataset1.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df2  = pd.read_csv(path + \"walking/dataset2.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df3  = pd.read_csv(path + \"walking/dataset3.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df4  = pd.read_csv(path + \"walking/dataset4.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df5  = pd.read_csv(path + \"walking/dataset5.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df6  = pd.read_csv(path + \"walking/dataset6.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df7  = pd.read_csv(path + \"walking/dataset7.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df8  = pd.read_csv(path + \"walking/dataset8.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df9  = pd.read_csv(path + \"walking/dataset9.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df10 = pd.read_csv(path + \"walking/dataset10.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df11 = pd.read_csv(path + \"walking/dataset11.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df12 = pd.read_csv(path + \"walking/dataset12.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df13 = pd.read_csv(path + \"walking/dataset13.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df14 = pd.read_csv(path + \"walking/dataset14.csv\", skiprows=4, header=0, names=col); \n",
    "walking_df15 = pd.read_csv(path + \"walking/dataset15.csv\", skiprows=4, header=0, names=col); \n",
    "walking_test_df = pd.concat([walking_df1,walking_df2,walking_df3]) \n",
    "walking_train_df = pd.concat([walking_df4,walking_df5,walking_df6,walking_df7\n",
    "                              ,walking_df8,walking_df9,walking_df10,walking_df11\n",
    "                                ,walking_df12,walking_df13,walking_df14,walking_df15])\n",
    "\n",
    "\n",
    "\n",
    "cycling_df1  = pd.read_csv(path + \"cycling/dataset1.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df2  = pd.read_csv(path + \"cycling/dataset2.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df3  = pd.read_csv(path + \"cycling/dataset3.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df4  = pd.read_csv(path + \"cycling/dataset4.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df5  = pd.read_csv(path + \"cycling/dataset5.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df6  = pd.read_csv(path + \"cycling/dataset6.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df7  = pd.read_csv(path + \"cycling/dataset7.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df8  = pd.read_csv(path + \"cycling/dataset8.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df9  = pd.read_csv(path + \"cycling/dataset9.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df10 = pd.read_csv(path + \"cycling/dataset10.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df11 = pd.read_csv(path + \"cycling/dataset11.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df12 = pd.read_csv(path + \"cycling/dataset12.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df13 = pd.read_csv(path + \"cycling/dataset13.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df14 = pd.read_csv(path + \"cycling/dataset14.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_df15 = pd.read_csv(path + \"cycling/dataset15.csv\", skiprows=4, header=0, names=col); \n",
    "cycling_test_df = pd.concat([cycling_df1,cycling_df2,cycling_df3]) \n",
    "cycling_train_df = pd.concat([cycling_df4,cycling_df5,cycling_df6,cycling_df7\n",
    "                              ,cycling_df8,cycling_df9,cycling_df10,cycling_df11\n",
    "                                ,cycling_df12,cycling_df13,cycling_df14,cycling_df15])\n",
    "\n",
    "\n",
    "lying_df1  = pd.read_csv(path + \"lying/dataset1.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df2  = pd.read_csv(path + \"lying/dataset2.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df3  = pd.read_csv(path + \"lying/dataset3.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df4  = pd.read_csv(path + \"lying/dataset4.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df5  = pd.read_csv(path + \"lying/dataset5.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df6  = pd.read_csv(path + \"lying/dataset6.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df7  = pd.read_csv(path + \"lying/dataset7.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df8  = pd.read_csv(path + \"lying/dataset8.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df9  = pd.read_csv(path + \"lying/dataset9.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df10 = pd.read_csv(path + \"lying/dataset10.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df11 = pd.read_csv(path + \"lying/dataset11.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df12 = pd.read_csv(path + \"lying/dataset12.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df13 = pd.read_csv(path + \"lying/dataset13.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df14 = pd.read_csv(path + \"lying/dataset14.csv\", skiprows=4, header=0, names=col); \n",
    "lying_df15 = pd.read_csv(path + \"lying/dataset15.csv\", skiprows=4, header=0, names=col); \n",
    "lying_test_df = pd.concat([lying_df1,lying_df2,lying_df3]) \n",
    "lying_train_df = pd.concat([lying_df4,lying_df5,lying_df6,lying_df7\n",
    "                              ,lying_df8,lying_df9,lying_df10,lying_df11\n",
    "                                ,lying_df12,lying_df13,lying_df14,lying_df15])\n",
    "\n",
    "\n",
    "sitting_df1  = pd.read_csv(path + \"sitting/dataset1.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df2  = pd.read_csv(path + \"sitting/dataset2.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df3  = pd.read_csv(path + \"sitting/dataset3.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df4  = pd.read_csv(path + \"sitting/dataset4.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df5  = pd.read_csv(path + \"sitting/dataset5.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df6  = pd.read_csv(path + \"sitting/dataset6.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df7  = pd.read_csv(path + \"sitting/dataset7.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df8  = pd.read_csv(path + \"sitting/dataset8.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df9  = pd.read_csv(path + \"sitting/dataset9.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df10 = pd.read_csv(path + \"sitting/dataset10.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df11 = pd.read_csv(path + \"sitting/dataset11.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df12 = pd.read_csv(path + \"sitting/dataset12.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df13 = pd.read_csv(path + \"sitting/dataset13.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df14 = pd.read_csv(path + \"sitting/dataset14.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_df15 = pd.read_csv(path + \"sitting/dataset15.csv\", skiprows=4, header=0, names=col); \n",
    "sitting_test_df = pd.concat([sitting_df1,sitting_df2,sitting_df3]) \n",
    "sitting_train_df = pd.concat([sitting_df4,sitting_df5,sitting_df6,sitting_df7\n",
    "                              ,sitting_df8,sitting_df9,sitting_df10,sitting_df11\n",
    "                                ,sitting_df12,sitting_df13,sitting_df14,sitting_df15])\n",
    "\n",
    "\n",
    "standing_df1  = pd.read_csv(path + \"standing/dataset1.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df2  = pd.read_csv(path + \"standing/dataset2.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df3  = pd.read_csv(path + \"standing/dataset3.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df4  = pd.read_csv(path + \"standing/dataset4.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df5  = pd.read_csv(path + \"standing/dataset5.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df6  = pd.read_csv(path + \"standing/dataset6.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df7  = pd.read_csv(path + \"standing/dataset7.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df8  = pd.read_csv(path + \"standing/dataset8.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df9  = pd.read_csv(path + \"standing/dataset9.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df10 = pd.read_csv(path + \"standing/dataset10.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df11 = pd.read_csv(path + \"standing/dataset11.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df12 = pd.read_csv(path + \"standing/dataset12.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df13 = pd.read_csv(path + \"standing/dataset13.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df14 = pd.read_csv(path + \"standing/dataset14.csv\", skiprows=4, header=0, names=col); \n",
    "standing_df15 = pd.read_csv(path + \"standing/dataset15.csv\", skiprows=4, header=0, names=col); \n",
    "standing_test_df = pd.concat([standing_df1,standing_df2,standing_df3]) \n",
    "standing_train_df = pd.concat([standing_df4,standing_df5,standing_df6,standing_df7\n",
    "                              ,standing_df8,standing_df9,standing_df10,standing_df11\n",
    "                                ,standing_df12,standing_df13,standing_df14,standing_df15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119750.]\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction and Dataset Creation\n",
    "import numpy as np\n",
    "\n",
    "bending1_df1 = pd.read_csv(path + \"bending1/dataset1.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df2 = pd.read_csv(path + \"bending1/dataset2.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df3 = pd.read_csv(path + \"bending1/dataset3.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df4 = pd.read_csv(path + \"bending1/dataset4.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df5 = pd.read_csv(path + \"bending1/dataset5.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df6 = pd.read_csv(path + \"bending1/dataset6.csv\", skiprows=4, header=0, names=col).values; \n",
    "bending1_df7 = pd.read_csv(path + \"bending1/dataset7.csv\", skiprows=4, header=0, names=col).values; \n",
    "\n",
    "print(max(bending1_df1[:,0:1]));\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
